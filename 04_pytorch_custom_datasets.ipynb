{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObe3y+Kx7EcjroMhmZvNqN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#04. PyTorch Custom Datasets\n",
        "\n",
        "\n",
        "Find a dataset, turn the dataset into numbers, build a model (or find an existing model) to find patterns in those numbers that can be used for prediction. PyTorch has many built-in datasets used for a wide number of machine learning benchmarks, however, you'll often want to use your own custom dataset.\n",
        "\n",
        "##What is a custom dataset?\n",
        "A custom dataset is a collection of data relating to a specific problem you're working on. In essence, a custom dataset can be comprised of almost anything. For example, if we were building a food image classification app like [Nutrify](https://nutrify.app/), our custom dataset might be images of food. Or if we were trying to build a model to classify whether or not a text-based review on a website was positive or negative, our custom dataset might be examples of existing customer reviews and their ratings.\n",
        "\n",
        "Or if we were trying to build a sound classification app, our custom dataset might be sound samples alongside their sample labels.\n",
        "\n",
        "Or if we were trying to build a recommendation system for customers purchasing things on our website, our custom dataset might be examples of products other people have bought.\n",
        "\n",
        "PyTorch includes many existing functions to load in various custom datasets in the `TorchVision`, `TorchText`, `TorchAudio` and `TorchRec` domain libraries.\n",
        "But sometimes these existing functions may not be enough. In that case, we can always subclass `torch.utils.data.Dataset` and customize it to our liking.\n",
        "\n",
        "What we're going to cover in this notebook\n",
        "We're going to be applying the PyTorch Workflow we covered in notebook 01 and notebook 02 to a computer vision problem. But instead of using an in-built PyTorch dataset, we're going to be using our own dataset of pizza, steak and sushi images. The goal will be to load these images and then build a model to train and predict on them.\n",
        "\n",
        "What we're going to build. We'll use `torchvision.datasets` as well as our own custom Dataset class to load in images of food and then we'll build a PyTorch computer vision model to hopefully be able to classify them.\n"
      ],
      "metadata": {
        "id": "NJ0S-OkMO4Gi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specifically, we're going to cover:\n",
        "\n",
        "**0. Importing PyTorch and setting up device-agnostic code**\n",
        "Let's get PyTorch loaded and then follow best practice to setup our code to be device-agnostic.\n",
        "\n",
        "**1. Get data**\n",
        "\n",
        "We're going to be using our own custom dataset of pizza, steak and sushi images.\n",
        "\n",
        "**2. Become one with the data (data preparation)**\n",
        "\n",
        "At the beginning of any new machine learning problem, it's paramount to understand the data you're working with. Here we'll take some steps to figure out what data we have.\n",
        "\n",
        "**3. Transforming data**\n",
        "\n",
        "Often, the data you get won't be 100% ready to use with a machine learning model, here we'll look at some steps we can take to transform our images so they're ready to be used with a model.\n",
        "\n",
        "**4. Loading data with ImageFolder (option 1)**\n",
        "\n",
        "PyTorch has many in-built data loading functions for common types of data. ImageFolder is helpful if our images are in standard image classification format.\n",
        "\n",
        "**5. Loading image data with a custom Dataset**\n",
        "\n",
        "What if PyTorch didn't have an in-built function to load data with? This is where we can build our own custom subclass of torch.utils.data.Dataset.\n",
        "\n",
        "**6. Other forms of transforms (data augmentation)**\n",
        "\n",
        "Data augmentation is a common technique for expanding the diversity of your training data. Here we'll explore some of torchvision's in-built data augmentation functions.\n",
        "\n",
        "**7. Model 0: TinyVGG without data augmentation**\n",
        "\n",
        "By this stage, we'll have our data ready, let's build a model capable of fitting it. We'll also create some training and testing functions for training and evaluating our model.\n",
        "\n",
        "**8. Exploring loss curves**\n",
        "\n",
        "Loss curves are a great way to see how your model is training/improving over time. They're also a good way to see if your model is **underfitting** or **overfitting**.\n",
        "\n",
        "**9. Model 1: TinyVGG with data augmentation**\n",
        "\n",
        "By now, we've tried a model without, how about we try one with data augmentation?\n",
        "\n",
        "**10. Compare model results**\n",
        "\n",
        "Let's compare our different models' loss curves and see which performed better and discuss some options for improving performance.\n",
        "\n",
        "**11. Making a prediction on a custom image**\n",
        "\n",
        "Our model is trained to on a dataset of pizza, steak and sushi images. In this section we'll cover how to use our trained model to predict on an image outside of our existing dataset."
      ],
      "metadata": {
        "id": "WH9gpx4QQafG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCxzBrZLOjM7"
      },
      "outputs": [],
      "source": []
    }
  ]
}